import pandas as pd
import numpy as np
import torch
from torch import nn
from torch_geometric.data import Data
from torch_geometric.nn import TransformerConv, global_mean_pool
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# =====================================================
# 1Ô∏è‚É£ ƒê·ªåC D·ªÆ LI·ªÜU
# =====================================================
DATA_PATH = "NF-ToN-IoT-v2-train.csv"   # ho·∫∑c NF-ToN-IoT-v2-train.csv
df = pd.read_csv(DATA_PATH, nrows=50000)  # ƒë·ªçc demo 50k d√≤ng

# X√°c ƒë·ªãnh c·ªôt nh√£n
label_col = [c for c in df.columns if "label" in c.lower() or "attack" in c.lower()]
if len(label_col) == 0:
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt nh√£n. H√£y ki·ªÉm tra t√™n c·ªôt trong file.")
df = df.rename(columns={label_col[0]: "label"})

# Encode label
le = LabelEncoder()
df["y"] = le.fit_transform(df["label"].astype(str))
print(f"üü¢ ƒê√£ m√£ h√≥a {len(le.classes_)} l·ªõp:", le.classes_)

# =====================================================
# 2Ô∏è‚É£ L√ÄM S·∫†CH D·ªÆ LI·ªÜU S·ªê
# =====================================================
feature_cols = [c for c in df.columns if c not in ["label", "y"]]
X = df[feature_cols].copy()

# √âp to√†n b·ªô v·ªÅ d·∫°ng s·ªë
for c in X.columns:
    X[c] = pd.to_numeric(X[c], errors='coerce')

# Thay th·∫ø NaN, Inf, gi√° tr·ªã c·ª±c l·ªõn
X = X.replace([np.inf, -np.inf, np.nan], 0)
X = np.clip(X, -1e9, 1e9)
X = X.astype(np.float32)

# Chu·∫©n h√≥a
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Tensor h√≥a
X_tensor = torch.tensor(X_scaled, dtype=torch.float)
y_tensor = torch.tensor(df["y"].values, dtype=torch.long)

num_nodes = X_tensor.shape[0]
num_features = X_tensor.shape[1]
num_classes = len(le.classes_)
print(f"‚úÖ Node: {num_nodes} | Feature: {num_features} | L·ªõp: {num_classes}")

# =====================================================
# 3Ô∏è‚É£ T·∫†O EDGE GI·∫¢ L·∫¨P D·ª∞A TR√äN SIMILARITY
# =====================================================
from sklearn.neighbors import NearestNeighbors

k = 5  # s·ªë l√°ng gi·ªÅng
nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(X_scaled)
distances, indices = nbrs.kneighbors(X_scaled)

edge_index = []
for i in range(num_nodes):
    for j in indices[i][1:]:  # b·ªè ch√≠nh n√≥
        edge_index.append([i, j])

edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()

# =====================================================
# 4Ô∏è‚É£ T·∫†O GRAPH DATA
# =====================================================
data = Data(x=X_tensor, edge_index=edge_index, y=y_tensor)

# Train/Test Split
train_mask, test_mask = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)
data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)
data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)
data.train_mask[train_mask] = True
data.test_mask[test_mask] = True

print(f"üß© Train nodes: {data.train_mask.sum()} | Test nodes: {data.test_mask.sum()}")

# =====================================================
# 5Ô∏è‚É£ M√î H√åNH GRAPH TRANSFORMER
# =====================================================
class GraphTransformer(nn.Module):
    def __init__(self, in_channels, hidden_channels, num_classes, heads=4, dropout=0.3):
        super().__init__()
        self.conv1 = TransformerConv(in_channels, hidden_channels, heads=heads, dropout=dropout)
        self.conv2 = TransformerConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)
        self.lin = nn.Linear(hidden_channels * heads, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x, edge_index, batch=None):
        x = self.conv1(x, edge_index)
        x = torch.relu(x)
        x = self.dropout(x)
        x = self.conv2(x, edge_index)
        x = torch.relu(x)
        x = self.dropout(x)
        x = self.lin(x)
        return x

# =====================================================
# 6Ô∏è‚É£ TRAIN LOOP
# =====================================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GraphTransformer(num_features, 64, num_classes).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
criterion = nn.CrossEntropyLoss()

data = data.to(device)

for epoch in range(1, 11):  # train 10 epoch demo
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

    # Evaluate
    model.eval()
    pred = out.argmax(dim=1)
    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum().item()
    acc = correct / data.test_mask.sum().item()

    print(f"Epoch {epoch:02d} | Loss: {loss.item():.4f} | Test Acc: {acc:.4f}")

# =====================================================
# 7Ô∏è‚É£ ƒê√ÅNH GI√Å CU·ªêI C√ôNG
# =====================================================
model.eval()
pred = out.argmax(dim=1).cpu().numpy()
true = data.y.cpu().numpy()

print("\nüìä Classification Report:")
print(classification_report(true[data.test_mask.cpu().numpy()],
                            pred[data.test_mask.cpu().numpy()],
                            target_names=le.classes_))





#####################################
import pandas as pd
import numpy as np
import torch
from torch import nn
from torch_geometric.data import Data
from torch_geometric.nn import HypergraphConv, global_mean_pool
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.neighbors import NearestNeighbors

# =====================================================
# 1Ô∏è‚É£ ƒê·ªåC V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU
# =====================================================
DATA_PATH = "NF-ToN-IoT-v2.csv"
df = pd.read_csv(DATA_PATH, nrows=50000)

label_col = [c for c in df.columns if "label" in c.lower() or "attack" in c.lower()]
if len(label_col) == 0:
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt nh√£n.")
df = df.rename(columns={label_col[0]: "label"})

le = LabelEncoder()
df["y"] = le.fit_transform(df["label"].astype(str))

feature_cols = [c for c in df.columns if c not in ["label", "y"]]
X = df[feature_cols].copy()

# L√†m s·∫°ch d·ªØ li·ªáu
for c in X.columns:
    X[c] = pd.to_numeric(X[c], errors='coerce')
X = X.replace([np.inf, -np.inf, np.nan], 0)
X = np.clip(X, -1e9, 1e9).astype(np.float32)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_tensor = torch.tensor(X_scaled, dtype=torch.float)
y_tensor = torch.tensor(df["y"].values, dtype=torch.long)

num_nodes = X_tensor.shape[0]
num_features = X_tensor.shape[1]
num_classes = len(le.classes_)
print(f"‚úÖ Node: {num_nodes} | Feature: {num_features} | L·ªõp: {num_classes}")

# =====================================================
# 2Ô∏è‚É£ T·∫†O HYPEREDGE (m·ªói hyperedge n·ªëi k node g·∫ßn nhau)
# =====================================================
k = 5
nbrs = NearestNeighbors(n_neighbors=k+1).fit(X_scaled)
_, indices = nbrs.kneighbors(X_scaled)

# edge_index_hyper: (2, num_hyperedges*k)
# M·ªói node i s·∫Ω c√≥ 1 hyperedge id = i
hyperedges = []
for i in range(num_nodes):
    for j in indices[i][1:]:
        hyperedges.append([i, j])
hyperedges = torch.tensor(hyperedges, dtype=torch.long).t().contiguous()

# =====================================================
# 3Ô∏è‚É£ ƒê·ªäNH NGHƒ®A M√î H√åNH HYPERGRAPH
# =====================================================
class HyperGraphNet(nn.Module):
    def __init__(self, in_channels, hidden_channels, num_classes, dropout=0.3):
        super().__init__()
        self.hconv1 = HypergraphConv(in_channels, hidden_channels)
        self.hconv2 = HypergraphConv(hidden_channels, hidden_channels)
        self.lin = nn.Linear(hidden_channels, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x, edge_index):
        x = torch.relu(self.hconv1(x, edge_index))
        x = self.dropout(x)
        x = torch.relu(self.hconv2(x, edge_index))
        x = self.dropout(x)
        x = self.lin(x)
        return x

# =====================================================
# 4Ô∏è‚É£ TRAIN / TEST SPLIT
# =====================================================
train_mask, test_mask = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)
data = Data(x=X_tensor, edge_index=hyperedges, y=y_tensor)
data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)
data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)
data.train_mask[train_mask] = True
data.test_mask[test_mask] = True

# =====================================================
# 5Ô∏è‚É£ TRAINING LOOP
# =====================================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = HyperGraphNet(num_features, 64, num_classes).to(device)
data = data.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
criterion = nn.CrossEntropyLoss()

for epoch in range(1, 11):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

    model.eval()
    pred = out.argmax(dim=1)
    acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()
    print(f"Epoch {epoch:02d} | Loss: {loss.item():.4f} | Test Acc: {acc:.4f}")

# =====================================================
# 6Ô∏è‚É£ B√ÅO C√ÅO K·∫æT QU·∫¢
# =====================================================
model.eval()
pred = out.argmax(dim=1).cpu().numpy()
true = data.y.cpu().numpy()
print("\nüìä Classification Report:")
print(classification_report(true[data.test_mask.cpu().numpy()],
                            pred[data.test_mask.cpu().numpy()],
                            target_names=le.classes_))
